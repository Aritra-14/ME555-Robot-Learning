{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Author: Aritra Ray**\n",
        "Description: Using Pix2PixHD Model for Next Frame in Sequence Prediction, on Glitch-Circle-White video\n",
        "\n",
        "\n",
        "Details of Pix2PixHD: https://github.com/NVIDIA/pix2pixHD"
      ],
      "metadata": {
        "id": "INT1OGcEXT_j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOexYWJX3Pt"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K--AsrIzpH58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65defb7-e598-49b8-855a-7e8b7760aab4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9D_7iUQINoa"
      },
      "source": [
        "Check to see what GPU we’re assigned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABG3hL4lIQGP",
        "outputId": "1bacdbea-e9d4-4fd8-bd83-c9e77fdb6c14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: A100-SXM4-40GB (UUID: GPU-2cef4060-1bef-4f00-51c9-68d9f8d77763)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUvLbCJtLqaV"
      },
      "source": [
        "## Install libraries and dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQbRsmWdvjUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aad2509-6a55-43b2-e292-21fbd9e9ce5c"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/nfp-colab/pix2pixHD/\"):\n",
        "    %cd /content/drive/MyDrive/nfp-colab/pix2pixHD/\n",
        "    # !git pull\n",
        "    !pip install dominate\n",
        "else:\n",
        "    %cd /content/drive/MyDrive\n",
        "    !mkdir nfp-colab\n",
        "    %cd nfp-colab\n",
        "    !git clone -b video https://github.com/dvschultz/pix2pixHD.git\n",
        "    !pip install dominate\n",
        "    %cd pix2pixHD/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nfp-colab/pix2pixHD\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dominate\n",
            "  Downloading dominate-2.7.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzLGf05WXMFV"
      },
      "source": [
        "## Extract frames from video\n",
        "\n",
        "Upload a video to either Colab or Google Drive.\n",
        "\n",
        "* `-video` is the path to the video file\n",
        "* `-name` should be a unique name (think of it like a project name)\n",
        "* `-width` and `-height` **must** to be a multiple of 32\n",
        "* `-p2pdir` leave as `.` unless you know it shouldn’t be that ;)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRL2ty6N9LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87cff8b-5f16-46e6-a071-c6d7171db52e"
      },
      "source": [
        "!python extract_frames.py -video /content/glitch-circle-white-720.mov -name glitch-circle-white -p2pdir . -width 1280 -height 736"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating the dataset structure\n",
            "ffmpeg -v 16 -i /content/glitch-circle-white-720.mov -q:v 2 -vf \"scale=iw*736/ih:736, crop=1280:736\" /content/drive/MyDrive/nfp-colab/pix2pixHD/datasets/glitch-circle-white/train_frames/frame-%06d.jpg -hide_banner\n",
            "extracting the frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL9BZkBA_QRR"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7qahzMX05u"
      },
      "source": [
        "### Initial training\n",
        "\n",
        "Note: if you have a large dataset, this may timeout initially (`ValueError: __len__() should return >= 0`). Give it a minute or two and run it again.\n",
        "\n",
        "*   `--name` should be a unique name (think of it like a project name). For your sanity I recommend using the same `-name` as above.\n",
        "*   `--dataroot` should point to your dataset. This will usually be in `./datasets/[your project name]`\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzHBGVnUKEzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00996726-6a44-40f5-f236-f85ce56b8da6"
      },
      "source": [
        "!python train_video.py --name glitch-circle-white --dataroot ./datasets/glitch-circle-white/ --save_epoch_freq 5 #--continue_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: False\n",
            "data_type: 32\n",
            "dataroot: ./datasets/glitch-circle-white/\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "fps: 24.0\n",
            "gpu_ids: [0]\n",
            "heat_seeking_lvl: 0\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 35\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: glitch-circle-white\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: False\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "pstart: 1\n",
            "pstop: 1\n",
            "resize_or_crop: scale_width\n",
            "save_epoch_freq: 5\n",
            "save_latest_freq: 1000\n",
            "scheduled_sampling: False\n",
            "serial_batches: False\n",
            "ss_recursion_prob: 0.2\n",
            "start_frames_before: 1\n",
            "start_from: video\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "video_mode: False\n",
            "which_epoch: latest\n",
            "zoom_cres: False\n",
            "zoom_inc: 24\n",
            "zoom_lvl: 0\n",
            "-------------- End ----------------\n",
            "train_video.py:11: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
            "  def lcm(a,b): return abs(a * b)/fractions.gcd(a,b) if a and b else 0\n",
            "CustomDatasetDataLoader\n",
            "dataset [FrameDataset] was created\n",
            "FrameDataset initialized from: ./datasets/glitch-circle-white/train_frames\n",
            "contains 300 frames, 299 consecutive pairs\n",
            "#training images = 299\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:04<00:00, 121MB/s] \n",
            "create web directory ./checkpoints/glitch-circle-white/web...\n",
            "(epoch: 1, iters: 100, time: 0.293) G_GAN: 0.607 G_GAN_Feat: 1.465 G_VGG: 2.692 D_real: 0.593 D_fake: 0.600 \n",
            "(epoch: 1, iters: 200, time: 0.204) G_GAN: 0.608 G_GAN_Feat: 1.243 G_VGG: 1.707 D_real: 0.558 D_fake: 0.534 \n",
            "End of epoch 1 / 200 \t Time Taken: 70 sec\n",
            "(epoch: 2, iters: 1, time: 0.206) G_GAN: 0.550 G_GAN_Feat: 1.128 G_VGG: 2.970 D_real: 0.492 D_fake: 0.502 \n",
            "(epoch: 2, iters: 101, time: 0.203) G_GAN: 0.541 G_GAN_Feat: 1.134 G_VGG: 1.345 D_real: 0.485 D_fake: 0.503 \n",
            "(epoch: 2, iters: 201, time: 0.203) G_GAN: 0.584 G_GAN_Feat: 1.168 G_VGG: 1.333 D_real: 0.534 D_fake: 0.518 \n",
            "End of epoch 2 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 3, iters: 2, time: 0.205) G_GAN: 0.575 G_GAN_Feat: 1.246 G_VGG: 1.253 D_real: 0.514 D_fake: 0.654 \n",
            "(epoch: 3, iters: 102, time: 0.203) G_GAN: 0.633 G_GAN_Feat: 1.328 G_VGG: 1.176 D_real: 0.556 D_fake: 0.599 \n",
            "(epoch: 3, iters: 202, time: 0.203) G_GAN: 0.657 G_GAN_Feat: 1.269 G_VGG: 1.169 D_real: 0.555 D_fake: 0.412 \n",
            "End of epoch 3 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 4, iters: 3, time: 0.205) G_GAN: 0.596 G_GAN_Feat: 1.388 G_VGG: 1.155 D_real: 0.445 D_fake: 0.469 \n",
            "(epoch: 4, iters: 103, time: 0.203) G_GAN: 0.638 G_GAN_Feat: 1.810 G_VGG: 1.256 D_real: 0.453 D_fake: 0.419 \n",
            "saving the latest model (epoch 4, total_steps 1000)\n",
            "(epoch: 4, iters: 203, time: 0.204) G_GAN: 0.520 G_GAN_Feat: 0.868 G_VGG: 1.204 D_real: 0.493 D_fake: 0.499 \n",
            "End of epoch 4 / 200 \t Time Taken: 82 sec\n",
            "(epoch: 5, iters: 4, time: 0.205) G_GAN: 0.545 G_GAN_Feat: 0.902 G_VGG: 1.158 D_real: 0.500 D_fake: 0.599 \n",
            "(epoch: 5, iters: 104, time: 0.203) G_GAN: 0.554 G_GAN_Feat: 0.952 G_VGG: 1.049 D_real: 0.457 D_fake: 0.499 \n",
            "(epoch: 5, iters: 204, time: 0.203) G_GAN: 0.575 G_GAN_Feat: 0.841 G_VGG: 1.009 D_real: 0.595 D_fake: 0.452 \n",
            "End of epoch 5 / 200 \t Time Taken: 60 sec\n",
            "saving the model at the end of epoch 5, iters 1495\n",
            "(epoch: 6, iters: 5, time: 0.311) G_GAN: 0.630 G_GAN_Feat: 1.011 G_VGG: 1.248 D_real: 0.535 D_fake: 0.433 \n",
            "(epoch: 6, iters: 105, time: 0.204) G_GAN: 0.499 G_GAN_Feat: 1.181 G_VGG: 1.043 D_real: 0.404 D_fake: 0.540 \n",
            "(epoch: 6, iters: 205, time: 0.204) G_GAN: 0.508 G_GAN_Feat: 1.308 G_VGG: 1.057 D_real: 0.419 D_fake: 0.509 \n",
            "End of epoch 6 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 7, iters: 6, time: 0.206) G_GAN: 0.400 G_GAN_Feat: 1.521 G_VGG: 1.106 D_real: 0.337 D_fake: 0.654 \n",
            "(epoch: 7, iters: 106, time: 0.203) G_GAN: 0.599 G_GAN_Feat: 1.244 G_VGG: 1.065 D_real: 0.506 D_fake: 0.626 \n",
            "(epoch: 7, iters: 206, time: 0.203) G_GAN: 0.481 G_GAN_Feat: 1.232 G_VGG: 1.051 D_real: 0.471 D_fake: 0.554 \n",
            "saving the latest model (epoch 7, total_steps 2000)\n",
            "End of epoch 7 / 200 \t Time Taken: 64 sec\n",
            "(epoch: 8, iters: 7, time: 0.207) G_GAN: 0.498 G_GAN_Feat: 1.545 G_VGG: 1.132 D_real: 0.430 D_fake: 0.643 \n",
            "(epoch: 8, iters: 107, time: 0.203) G_GAN: 0.595 G_GAN_Feat: 1.468 G_VGG: 1.100 D_real: 0.432 D_fake: 0.453 \n",
            "(epoch: 8, iters: 207, time: 0.203) G_GAN: 0.553 G_GAN_Feat: 1.321 G_VGG: 1.043 D_real: 0.479 D_fake: 0.478 \n",
            "End of epoch 8 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 9, iters: 8, time: 0.205) G_GAN: 0.500 G_GAN_Feat: 1.479 G_VGG: 1.093 D_real: 0.451 D_fake: 0.515 \n",
            "(epoch: 9, iters: 108, time: 0.203) G_GAN: 0.455 G_GAN_Feat: 1.388 G_VGG: 0.986 D_real: 0.447 D_fake: 0.662 \n",
            "(epoch: 9, iters: 208, time: 0.203) G_GAN: 0.603 G_GAN_Feat: 1.639 G_VGG: 1.115 D_real: 0.469 D_fake: 0.426 \n",
            "End of epoch 9 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 10, iters: 9, time: 0.206) G_GAN: 0.717 G_GAN_Feat: 1.410 G_VGG: 1.003 D_real: 0.666 D_fake: 0.894 \n",
            "(epoch: 10, iters: 109, time: 0.203) G_GAN: 0.747 G_GAN_Feat: 1.430 G_VGG: 1.064 D_real: 0.682 D_fake: 0.656 \n",
            "(epoch: 10, iters: 209, time: 0.203) G_GAN: 0.743 G_GAN_Feat: 1.905 G_VGG: 1.030 D_real: 0.666 D_fake: 0.574 \n",
            "End of epoch 10 / 200 \t Time Taken: 60 sec\n",
            "saving the model at the end of epoch 10, iters 2990\n",
            "(epoch: 11, iters: 10, time: 0.259) G_GAN: 1.002 G_GAN_Feat: 1.595 G_VGG: 1.066 D_real: 0.756 D_fake: 0.512 \n",
            "saving the latest model (epoch 11, total_steps 3000)\n",
            "(epoch: 11, iters: 110, time: 0.203) G_GAN: 0.623 G_GAN_Feat: 1.729 G_VGG: 1.099 D_real: 0.447 D_fake: 0.519 \n",
            "(epoch: 11, iters: 210, time: 0.203) G_GAN: 0.605 G_GAN_Feat: 1.552 G_VGG: 0.962 D_real: 0.487 D_fake: 0.599 \n",
            "End of epoch 11 / 200 \t Time Taken: 66 sec\n",
            "(epoch: 12, iters: 11, time: 0.206) G_GAN: 0.619 G_GAN_Feat: 1.660 G_VGG: 1.014 D_real: 0.586 D_fake: 0.425 \n",
            "(epoch: 12, iters: 111, time: 0.203) G_GAN: 0.557 G_GAN_Feat: 1.559 G_VGG: 1.027 D_real: 0.416 D_fake: 0.525 \n",
            "(epoch: 12, iters: 211, time: 0.203) G_GAN: 0.618 G_GAN_Feat: 1.760 G_VGG: 1.009 D_real: 0.516 D_fake: 0.445 \n",
            "End of epoch 12 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 13, iters: 12, time: 0.205) G_GAN: 0.544 G_GAN_Feat: 1.758 G_VGG: 1.064 D_real: 0.455 D_fake: 0.637 \n",
            "(epoch: 13, iters: 112, time: 0.203) G_GAN: 0.558 G_GAN_Feat: 2.053 G_VGG: 1.092 D_real: 0.458 D_fake: 0.535 \n",
            "(epoch: 13, iters: 212, time: 0.203) G_GAN: 0.525 G_GAN_Feat: 1.783 G_VGG: 1.014 D_real: 0.460 D_fake: 0.505 \n",
            "End of epoch 13 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 14, iters: 13, time: 0.206) G_GAN: 0.676 G_GAN_Feat: 1.971 G_VGG: 0.960 D_real: 0.646 D_fake: 0.428 \n",
            "(epoch: 14, iters: 113, time: 0.203) G_GAN: 0.552 G_GAN_Feat: 2.154 G_VGG: 1.087 D_real: 0.487 D_fake: 0.688 \n",
            "saving the latest model (epoch 14, total_steps 4000)\n",
            "(epoch: 14, iters: 213, time: 0.204) G_GAN: 0.749 G_GAN_Feat: 2.395 G_VGG: 1.070 D_real: 0.576 D_fake: 0.368 \n",
            "End of epoch 14 / 200 \t Time Taken: 65 sec\n",
            "(epoch: 15, iters: 14, time: 0.206) G_GAN: 0.612 G_GAN_Feat: 1.845 G_VGG: 0.962 D_real: 0.522 D_fake: 0.430 \n",
            "(epoch: 15, iters: 114, time: 0.204) G_GAN: 0.410 G_GAN_Feat: 2.281 G_VGG: 1.018 D_real: 0.355 D_fake: 0.679 \n",
            "(epoch: 15, iters: 214, time: 0.204) G_GAN: 0.648 G_GAN_Feat: 1.729 G_VGG: 1.005 D_real: 0.538 D_fake: 0.510 \n",
            "End of epoch 15 / 200 \t Time Taken: 61 sec\n",
            "saving the model at the end of epoch 15, iters 4485\n",
            "(epoch: 16, iters: 15, time: 0.260) G_GAN: 0.544 G_GAN_Feat: 0.815 G_VGG: 0.944 D_real: 0.521 D_fake: 0.496 \n",
            "(epoch: 16, iters: 115, time: 0.204) G_GAN: 0.586 G_GAN_Feat: 1.670 G_VGG: 0.990 D_real: 0.461 D_fake: 0.477 \n",
            "(epoch: 16, iters: 215, time: 0.204) G_GAN: 0.548 G_GAN_Feat: 2.056 G_VGG: 1.008 D_real: 0.462 D_fake: 0.582 \n",
            "End of epoch 16 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 17, iters: 16, time: 0.206) G_GAN: 0.717 G_GAN_Feat: 1.826 G_VGG: 0.951 D_real: 0.658 D_fake: 0.367 \n",
            "(epoch: 17, iters: 116, time: 0.204) G_GAN: 0.601 G_GAN_Feat: 1.793 G_VGG: 0.924 D_real: 0.559 D_fake: 0.575 \n",
            "(epoch: 17, iters: 216, time: 0.204) G_GAN: 0.811 G_GAN_Feat: 1.969 G_VGG: 1.074 D_real: 0.622 D_fake: 0.433 \n",
            "saving the latest model (epoch 17, total_steps 5000)\n",
            "End of epoch 17 / 200 \t Time Taken: 64 sec\n",
            "(epoch: 18, iters: 17, time: 0.207) G_GAN: 0.926 G_GAN_Feat: 2.068 G_VGG: 0.953 D_real: 0.603 D_fake: 0.362 \n",
            "(epoch: 18, iters: 117, time: 0.203) G_GAN: 0.642 G_GAN_Feat: 2.477 G_VGG: 0.963 D_real: 0.410 D_fake: 0.435 \n",
            "(epoch: 18, iters: 217, time: 0.203) G_GAN: 0.634 G_GAN_Feat: 1.939 G_VGG: 0.961 D_real: 0.488 D_fake: 0.521 \n",
            "End of epoch 18 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 19, iters: 18, time: 0.206) G_GAN: 0.633 G_GAN_Feat: 1.813 G_VGG: 0.887 D_real: 0.560 D_fake: 0.419 \n",
            "(epoch: 19, iters: 118, time: 0.203) G_GAN: 0.497 G_GAN_Feat: 0.563 G_VGG: 1.117 D_real: 0.492 D_fake: 0.524 \n",
            "(epoch: 19, iters: 218, time: 0.203) G_GAN: 0.781 G_GAN_Feat: 0.687 G_VGG: 0.965 D_real: 0.762 D_fake: 0.792 \n",
            "End of epoch 19 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 20, iters: 19, time: 0.206) G_GAN: 0.524 G_GAN_Feat: 0.748 G_VGG: 0.990 D_real: 0.475 D_fake: 0.494 \n",
            "(epoch: 20, iters: 119, time: 0.203) G_GAN: 0.489 G_GAN_Feat: 0.919 G_VGG: 0.933 D_real: 0.476 D_fake: 0.523 \n",
            "(epoch: 20, iters: 219, time: 0.203) G_GAN: 0.474 G_GAN_Feat: 1.093 G_VGG: 1.001 D_real: 0.424 D_fake: 0.537 \n",
            "End of epoch 20 / 200 \t Time Taken: 60 sec\n",
            "saving the model at the end of epoch 20, iters 5980\n",
            "(epoch: 21, iters: 20, time: 0.258) G_GAN: 0.519 G_GAN_Feat: 1.202 G_VGG: 0.924 D_real: 0.483 D_fake: 0.490 \n",
            "saving the latest model (epoch 21, total_steps 6000)\n",
            "(epoch: 21, iters: 120, time: 0.203) G_GAN: 0.635 G_GAN_Feat: 1.056 G_VGG: 0.941 D_real: 0.595 D_fake: 0.495 \n",
            "(epoch: 21, iters: 220, time: 0.203) G_GAN: 0.496 G_GAN_Feat: 1.085 G_VGG: 0.895 D_real: 0.478 D_fake: 0.517 \n",
            "End of epoch 21 / 200 \t Time Taken: 64 sec\n",
            "(epoch: 22, iters: 21, time: 0.206) G_GAN: 0.608 G_GAN_Feat: 0.966 G_VGG: 0.938 D_real: 0.552 D_fake: 0.417 \n",
            "(epoch: 22, iters: 121, time: 0.203) G_GAN: 0.534 G_GAN_Feat: 1.199 G_VGG: 0.877 D_real: 0.571 D_fake: 0.548 \n",
            "(epoch: 22, iters: 221, time: 0.203) G_GAN: 0.566 G_GAN_Feat: 1.301 G_VGG: 0.884 D_real: 0.469 D_fake: 0.538 \n",
            "End of epoch 22 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 23, iters: 22, time: 0.206) G_GAN: 0.551 G_GAN_Feat: 1.284 G_VGG: 0.891 D_real: 0.552 D_fake: 0.534 \n",
            "(epoch: 23, iters: 122, time: 0.203) G_GAN: 0.634 G_GAN_Feat: 1.540 G_VGG: 1.018 D_real: 0.504 D_fake: 0.449 \n",
            "(epoch: 23, iters: 222, time: 0.203) G_GAN: 0.478 G_GAN_Feat: 1.360 G_VGG: 0.897 D_real: 0.402 D_fake: 0.567 \n",
            "End of epoch 23 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 24, iters: 23, time: 0.206) G_GAN: 0.478 G_GAN_Feat: 1.759 G_VGG: 0.910 D_real: 0.439 D_fake: 0.551 \n",
            "(epoch: 24, iters: 123, time: 0.203) G_GAN: 0.520 G_GAN_Feat: 2.418 G_VGG: 0.937 D_real: 0.324 D_fake: 0.526 \n",
            "saving the latest model (epoch 24, total_steps 7000)\n",
            "(epoch: 24, iters: 223, time: 0.203) G_GAN: 0.526 G_GAN_Feat: 1.711 G_VGG: 0.934 D_real: 0.478 D_fake: 0.509 \n",
            "End of epoch 24 / 200 \t Time Taken: 64 sec\n",
            "(epoch: 25, iters: 24, time: 0.206) G_GAN: 0.841 G_GAN_Feat: 2.306 G_VGG: 0.950 D_real: 0.864 D_fake: 0.516 \n",
            "(epoch: 25, iters: 124, time: 0.203) G_GAN: 0.596 G_GAN_Feat: 2.527 G_VGG: 1.096 D_real: 0.484 D_fake: 0.596 \n",
            "(epoch: 25, iters: 224, time: 0.203) G_GAN: 0.674 G_GAN_Feat: 1.883 G_VGG: 0.969 D_real: 0.575 D_fake: 0.370 \n",
            "End of epoch 25 / 200 \t Time Taken: 60 sec\n",
            "saving the model at the end of epoch 25, iters 7475\n",
            "(epoch: 26, iters: 25, time: 0.267) G_GAN: 0.998 G_GAN_Feat: 2.833 G_VGG: 0.867 D_real: 0.715 D_fake: 0.246 \n",
            "(epoch: 26, iters: 125, time: 0.203) G_GAN: 0.783 G_GAN_Feat: 3.134 G_VGG: 0.995 D_real: 0.535 D_fake: 0.377 \n",
            "(epoch: 26, iters: 225, time: 0.203) G_GAN: 0.771 G_GAN_Feat: 3.063 G_VGG: 0.954 D_real: 0.462 D_fake: 0.342 \n",
            "End of epoch 26 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 27, iters: 26, time: 0.206) G_GAN: 0.969 G_GAN_Feat: 2.165 G_VGG: 0.918 D_real: 0.832 D_fake: 0.497 \n",
            "(epoch: 27, iters: 126, time: 0.203) G_GAN: 0.666 G_GAN_Feat: 1.491 G_VGG: 0.970 D_real: 0.560 D_fake: 0.421 \n",
            "(epoch: 27, iters: 226, time: 0.203) G_GAN: 0.495 G_GAN_Feat: 1.241 G_VGG: 0.960 D_real: 0.453 D_fake: 0.512 \n",
            "saving the latest model (epoch 27, total_steps 8000)\n",
            "End of epoch 27 / 200 \t Time Taken: 64 sec\n",
            "(epoch: 28, iters: 27, time: 0.206) G_GAN: 0.488 G_GAN_Feat: 1.970 G_VGG: 0.863 D_real: 0.473 D_fake: 0.582 \n",
            "(epoch: 28, iters: 127, time: 0.203) G_GAN: 0.586 G_GAN_Feat: 2.058 G_VGG: 0.909 D_real: 0.477 D_fake: 0.627 \n",
            "(epoch: 28, iters: 227, time: 0.203) G_GAN: 0.530 G_GAN_Feat: 1.886 G_VGG: 0.980 D_real: 0.416 D_fake: 0.516 \n",
            "End of epoch 28 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 29, iters: 28, time: 0.206) G_GAN: 0.484 G_GAN_Feat: 2.262 G_VGG: 0.895 D_real: 0.347 D_fake: 0.623 \n",
            "(epoch: 29, iters: 128, time: 0.203) G_GAN: 0.640 G_GAN_Feat: 2.690 G_VGG: 0.912 D_real: 0.399 D_fake: 0.518 \n",
            "(epoch: 29, iters: 228, time: 0.203) G_GAN: 0.648 G_GAN_Feat: 2.345 G_VGG: 0.954 D_real: 0.634 D_fake: 0.572 \n",
            "End of epoch 29 / 200 \t Time Taken: 60 sec\n",
            "(epoch: 30, iters: 29, time: 0.206) G_GAN: 0.784 G_GAN_Feat: 2.551 G_VGG: 0.955 D_real: 0.535 D_fake: 0.417 \n",
            "(epoch: 30, iters: 129, time: 0.203) G_GAN: 0.366 G_GAN_Feat: 2.863 G_VGG: 0.966 D_real: 0.343 D_fake: 0.773 \n",
            "(epoch: 30, iters: 229, time: 0.203) G_GAN: 0.639 G_GAN_Feat: 2.416 G_VGG: 0.967 D_real: 0.391 D_fake: 0.440 \n",
            "End of epoch 30 / 200 \t Time Taken: 60 sec\n",
            "saving the model at the end of epoch 30, iters 8970\n",
            "(epoch: 31, iters: 30, time: 0.258) G_GAN: 0.551 G_GAN_Feat: 2.671 G_VGG: 0.943 D_real: 0.462 D_fake: 0.570 \n",
            "saving the latest model (epoch 31, total_steps 9000)\n",
            "(epoch: 31, iters: 130, time: 0.204) G_GAN: 0.797 G_GAN_Feat: 2.778 G_VGG: 0.966 D_real: 0.659 D_fake: 0.335 \n",
            "(epoch: 31, iters: 230, time: 0.204) G_GAN: 0.570 G_GAN_Feat: 2.800 G_VGG: 0.946 D_real: 0.387 D_fake: 0.491 \n",
            "End of epoch 31 / 200 \t Time Taken: 65 sec\n",
            "(epoch: 32, iters: 31, time: 0.207) G_GAN: 0.624 G_GAN_Feat: 2.714 G_VGG: 1.009 D_real: 0.294 D_fake: 0.423 \n",
            "(epoch: 32, iters: 131, time: 0.204) G_GAN: 0.755 G_GAN_Feat: 2.406 G_VGG: 0.971 D_real: 0.688 D_fake: 0.427 \n",
            "(epoch: 32, iters: 231, time: 0.204) G_GAN: 0.644 G_GAN_Feat: 2.572 G_VGG: 0.959 D_real: 0.450 D_fake: 0.412 \n",
            "End of epoch 32 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 33, iters: 32, time: 0.207) G_GAN: 1.212 G_GAN_Feat: 2.175 G_VGG: 0.968 D_real: 0.705 D_fake: 0.192 \n",
            "(epoch: 33, iters: 132, time: 0.204) G_GAN: 0.752 G_GAN_Feat: 3.491 G_VGG: 0.955 D_real: 0.455 D_fake: 0.428 \n",
            "(epoch: 33, iters: 232, time: 0.204) G_GAN: 0.438 G_GAN_Feat: 2.591 G_VGG: 0.930 D_real: 0.315 D_fake: 0.638 \n",
            "End of epoch 33 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 34, iters: 33, time: 0.207) G_GAN: 0.885 G_GAN_Feat: 2.632 G_VGG: 0.965 D_real: 0.652 D_fake: 0.253 \n",
            "(epoch: 34, iters: 133, time: 0.204) G_GAN: 0.523 G_GAN_Feat: 2.714 G_VGG: 0.896 D_real: 0.335 D_fake: 0.518 \n",
            "saving the latest model (epoch 34, total_steps 10000)\n",
            "(epoch: 34, iters: 233, time: 0.204) G_GAN: 1.105 G_GAN_Feat: 2.246 G_VGG: 0.923 D_real: 0.678 D_fake: 0.241 \n",
            "End of epoch 34 / 200 \t Time Taken: 64 sec\n",
            "(epoch: 35, iters: 34, time: 0.207) G_GAN: 0.845 G_GAN_Feat: 2.392 G_VGG: 0.943 D_real: 0.592 D_fake: 0.290 \n",
            "(epoch: 35, iters: 134, time: 0.204) G_GAN: 0.523 G_GAN_Feat: 2.169 G_VGG: 0.981 D_real: 0.477 D_fake: 0.543 \n",
            "(epoch: 35, iters: 234, time: 0.204) G_GAN: 0.642 G_GAN_Feat: 2.453 G_VGG: 0.960 D_real: 0.431 D_fake: 0.396 \n",
            "End of epoch 35 / 200 \t Time Taken: 61 sec\n",
            "saving the model at the end of epoch 35, iters 10465\n",
            "(epoch: 36, iters: 35, time: 0.283) G_GAN: 0.435 G_GAN_Feat: 1.942 G_VGG: 0.892 D_real: 0.361 D_fake: 0.633 \n",
            "(epoch: 36, iters: 135, time: 0.204) G_GAN: 0.550 G_GAN_Feat: 1.904 G_VGG: 0.795 D_real: 0.420 D_fake: 0.512 \n",
            "(epoch: 36, iters: 235, time: 0.204) G_GAN: 0.590 G_GAN_Feat: 1.985 G_VGG: 0.867 D_real: 0.424 D_fake: 0.505 \n",
            "End of epoch 36 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 37, iters: 36, time: 0.207) G_GAN: 0.516 G_GAN_Feat: 1.147 G_VGG: 0.802 D_real: 0.592 D_fake: 0.492 \n",
            "(epoch: 37, iters: 136, time: 0.204) G_GAN: 0.396 G_GAN_Feat: 1.110 G_VGG: 0.840 D_real: 0.374 D_fake: 0.667 \n",
            "(epoch: 37, iters: 236, time: 0.204) G_GAN: 0.543 G_GAN_Feat: 1.405 G_VGG: 0.884 D_real: 0.410 D_fake: 0.472 \n",
            "saving the latest model (epoch 37, total_steps 11000)\n",
            "End of epoch 37 / 200 \t Time Taken: 64 sec\n",
            "(epoch: 38, iters: 37, time: 0.207) G_GAN: 0.373 G_GAN_Feat: 1.478 G_VGG: 0.857 D_real: 0.399 D_fake: 0.664 \n",
            "(epoch: 38, iters: 137, time: 0.204) G_GAN: 0.442 G_GAN_Feat: 1.364 G_VGG: 0.870 D_real: 0.363 D_fake: 0.595 \n",
            "(epoch: 38, iters: 237, time: 0.204) G_GAN: 0.609 G_GAN_Feat: 1.192 G_VGG: 0.829 D_real: 0.600 D_fake: 0.449 \n",
            "End of epoch 38 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 39, iters: 38, time: 0.207) G_GAN: 0.502 G_GAN_Feat: 1.492 G_VGG: 0.826 D_real: 0.403 D_fake: 0.512 \n",
            "(epoch: 39, iters: 138, time: 0.204) G_GAN: 0.625 G_GAN_Feat: 1.102 G_VGG: 0.755 D_real: 0.597 D_fake: 0.441 \n",
            "(epoch: 39, iters: 238, time: 0.204) G_GAN: 0.474 G_GAN_Feat: 1.661 G_VGG: 0.841 D_real: 0.337 D_fake: 0.574 \n",
            "End of epoch 39 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 40, iters: 39, time: 0.207) G_GAN: 0.639 G_GAN_Feat: 1.778 G_VGG: 0.800 D_real: 0.585 D_fake: 0.439 \n",
            "(epoch: 40, iters: 139, time: 0.204) G_GAN: 0.512 G_GAN_Feat: 1.876 G_VGG: 0.988 D_real: 0.327 D_fake: 0.574 \n",
            "(epoch: 40, iters: 239, time: 0.204) G_GAN: 0.514 G_GAN_Feat: 1.219 G_VGG: 0.893 D_real: 0.474 D_fake: 0.565 \n",
            "End of epoch 40 / 200 \t Time Taken: 61 sec\n",
            "saving the model at the end of epoch 40, iters 11960\n",
            "(epoch: 41, iters: 40, time: 0.278) G_GAN: 0.622 G_GAN_Feat: 1.460 G_VGG: 0.778 D_real: 0.645 D_fake: 0.434 \n",
            "saving the latest model (epoch 41, total_steps 12000)\n",
            "(epoch: 41, iters: 140, time: 0.204) G_GAN: 0.554 G_GAN_Feat: 1.447 G_VGG: 0.775 D_real: 0.539 D_fake: 0.461 \n",
            "(epoch: 41, iters: 240, time: 0.204) G_GAN: 0.609 G_GAN_Feat: 1.675 G_VGG: 0.850 D_real: 0.591 D_fake: 0.426 \n",
            "End of epoch 41 / 200 \t Time Taken: 67 sec\n",
            "(epoch: 42, iters: 41, time: 0.207) G_GAN: 0.706 G_GAN_Feat: 1.520 G_VGG: 0.856 D_real: 0.739 D_fake: 0.547 \n",
            "(epoch: 42, iters: 141, time: 0.204) G_GAN: 0.765 G_GAN_Feat: 1.719 G_VGG: 0.869 D_real: 0.690 D_fake: 0.327 \n",
            "(epoch: 42, iters: 241, time: 0.204) G_GAN: 0.559 G_GAN_Feat: 1.582 G_VGG: 0.844 D_real: 0.474 D_fake: 0.524 \n",
            "End of epoch 42 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 43, iters: 42, time: 0.206) G_GAN: 0.427 G_GAN_Feat: 1.529 G_VGG: 0.740 D_real: 0.381 D_fake: 0.685 \n",
            "(epoch: 43, iters: 142, time: 0.204) G_GAN: 0.479 G_GAN_Feat: 1.936 G_VGG: 0.754 D_real: 0.466 D_fake: 0.564 \n",
            "(epoch: 43, iters: 242, time: 0.203) G_GAN: 0.389 G_GAN_Feat: 2.308 G_VGG: 0.886 D_real: 0.327 D_fake: 0.797 \n",
            "End of epoch 43 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 44, iters: 43, time: 0.206) G_GAN: 0.536 G_GAN_Feat: 1.704 G_VGG: 0.752 D_real: 0.424 D_fake: 0.491 \n",
            "(epoch: 44, iters: 143, time: 0.203) G_GAN: 0.632 G_GAN_Feat: 0.961 G_VGG: 0.864 D_real: 0.594 D_fake: 0.558 \n",
            "saving the latest model (epoch 44, total_steps 13000)\n",
            "(epoch: 44, iters: 243, time: 0.203) G_GAN: 0.489 G_GAN_Feat: 1.031 G_VGG: 0.838 D_real: 0.412 D_fake: 0.539 \n",
            "End of epoch 44 / 200 \t Time Taken: 64 sec\n",
            "(epoch: 45, iters: 44, time: 0.206) G_GAN: 0.546 G_GAN_Feat: 1.211 G_VGG: 0.853 D_real: 0.519 D_fake: 0.495 \n",
            "(epoch: 45, iters: 144, time: 0.204) G_GAN: 0.676 G_GAN_Feat: 1.407 G_VGG: 0.854 D_real: 0.663 D_fake: 0.451 \n",
            "(epoch: 45, iters: 244, time: 0.204) G_GAN: 0.520 G_GAN_Feat: 1.244 G_VGG: 0.849 D_real: 0.487 D_fake: 0.642 \n",
            "End of epoch 45 / 200 \t Time Taken: 61 sec\n",
            "saving the model at the end of epoch 45, iters 13455\n",
            "(epoch: 46, iters: 45, time: 0.260) G_GAN: 0.501 G_GAN_Feat: 1.423 G_VGG: 0.778 D_real: 0.464 D_fake: 0.508 \n",
            "(epoch: 46, iters: 145, time: 0.204) G_GAN: 0.893 G_GAN_Feat: 1.425 G_VGG: 0.795 D_real: 0.853 D_fake: 1.077 \n",
            "(epoch: 46, iters: 245, time: 0.204) G_GAN: 0.774 G_GAN_Feat: 1.389 G_VGG: 0.799 D_real: 0.619 D_fake: 0.435 \n",
            "End of epoch 46 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 47, iters: 46, time: 0.207) G_GAN: 0.568 G_GAN_Feat: 1.769 G_VGG: 0.841 D_real: 0.382 D_fake: 0.515 \n",
            "(epoch: 47, iters: 146, time: 0.204) G_GAN: 0.587 G_GAN_Feat: 1.368 G_VGG: 0.766 D_real: 0.563 D_fake: 0.441 \n",
            "(epoch: 47, iters: 246, time: 0.204) G_GAN: 0.651 G_GAN_Feat: 2.199 G_VGG: 0.865 D_real: 0.588 D_fake: 0.508 \n",
            "saving the latest model (epoch 47, total_steps 14000)\n",
            "End of epoch 47 / 200 \t Time Taken: 67 sec\n",
            "(epoch: 48, iters: 47, time: 0.207) G_GAN: 0.613 G_GAN_Feat: 2.206 G_VGG: 0.791 D_real: 0.579 D_fake: 0.430 \n",
            "(epoch: 48, iters: 147, time: 0.204) G_GAN: 0.698 G_GAN_Feat: 1.863 G_VGG: 0.843 D_real: 0.620 D_fake: 0.388 \n",
            "(epoch: 48, iters: 247, time: 0.204) G_GAN: 0.338 G_GAN_Feat: 1.461 G_VGG: 0.767 D_real: 0.319 D_fake: 0.804 \n",
            "End of epoch 48 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 49, iters: 48, time: 0.206) G_GAN: 0.765 G_GAN_Feat: 1.707 G_VGG: 0.863 D_real: 0.665 D_fake: 0.568 \n",
            "(epoch: 49, iters: 148, time: 0.204) G_GAN: 0.793 G_GAN_Feat: 1.669 G_VGG: 0.823 D_real: 0.472 D_fake: 0.340 \n",
            "(epoch: 49, iters: 248, time: 0.204) G_GAN: 0.594 G_GAN_Feat: 1.832 G_VGG: 0.839 D_real: 0.494 D_fake: 0.435 \n",
            "End of epoch 49 / 200 \t Time Taken: 61 sec\n",
            "(epoch: 50, iters: 49, time: 0.207) G_GAN: 0.495 G_GAN_Feat: 1.653 G_VGG: 0.851 D_real: 0.432 D_fake: 0.540 \n",
            "(epoch: 50, iters: 149, time: 0.204) G_GAN: 0.790 G_GAN_Feat: 2.211 G_VGG: 0.797 D_real: 0.410 D_fake: 0.364 \n",
            "(epoch: 50, iters: 249, time: 0.204) G_GAN: 0.834 G_GAN_Feat: 1.913 G_VGG: 0.840 D_real: 0.586 D_fake: 0.406 \n",
            "End of epoch 50 / 200 \t Time Taken: 61 sec\n",
            "saving the model at the end of epoch 50, iters 14950\n",
            "(epoch: 51, iters: 50, time: 0.279) G_GAN: 0.462 G_GAN_Feat: 1.691 G_VGG: 0.795 D_real: 0.344 D_fake: 0.658 \n",
            "saving the latest model (epoch 51, total_steps 15000)\n",
            "Traceback (most recent call last):\n",
            "  File \"train_video.py\", line 145, in <module>\n",
            "    loss_D.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 396, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GDg3CeW_1TD"
      },
      "source": [
        "### Continue Training\n",
        "To pick up from a previous training session run the same command you ran to start with and append `--continue_train` to the end of the command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5q3dE9S_5eg"
      },
      "source": [
        "!python train_video.py --name vid1 --dataroot ./datasets/vid1/ --save_epoch_freq 1 --continue_train "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jly_3OyBoGg2"
      },
      "source": [
        "#Generating Videos\n",
        "\n",
        "To generate a video from your completed model, run the `generate_video.py` script. I recommend keeping the `--name` and `--dataroot` arguments the same.\n",
        "\n",
        "There are a number of additional arguments you’ll need to include in this command:\n",
        "\n",
        "\n",
        "*   `--fps` frame rate for your video\n",
        "*   `--how_many` how many frames you want to create (this + fps = video length)\n",
        "*   `--which_epoch` which epoch you want to generate videos from (note: if you choose `133` but there’s no epoch 133 model file, this will throw an error)\n",
        "*   `--start_from` by default your video will start predicting images from the 60th frame of your training set. You can pass in the path to a different frame to have it start from that frame\n",
        "\n",
        "Playing with both the `--which_epoch` and `--start_from` arguments gives diverse results\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INVUtG-pt_F6",
        "outputId": "f45c4784-5dcd-4b34-9d55-349321b39ba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python generate_video.py --name glitch-circle-white --dataroot ./datasets/glitch-circle-white/ --fps 24 --how_many 600 --which_epoch 50 --start_from 'video' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/glitch-circle-white/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "fps: 24.0\n",
            "gpu_ids: [0]\n",
            "heat_seeking_lvl: 0\n",
            "how_many: 600\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 35\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: glitch-circle-white\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_crop: True\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "png: False\n",
            "pstart: 1\n",
            "pstop: 1\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "scheduled_sampling: False\n",
            "serial_batches: False\n",
            "ss_recursion_prob: 0.2\n",
            "start_frames_before: 1\n",
            "start_from: video\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "video_mode: False\n",
            "which_epoch: 50\n",
            "zoom_cres: False\n",
            "zoom_inc: 24\n",
            "zoom_lvl: 0\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [FrameDataset] was created\n",
            "FrameDataset initialized from: ./datasets/glitch-circle-white/test_frames\n",
            "contains 60 frames, 59 consecutive pairs\n",
            "\n",
            "100% 600/600 [01:01<00:00,  9.75it/s]\n",
            "ffmpeg -v 16 -framerate 24 -i ./checkpoints/glitch-circle-white/frames/frame-%05d.jpg -ss 1 -q:v 2 -filter:v \"crop=1280:720:0:16\" ./checkpoints/glitch-circle-white/output/epoch-50_glitch-circle-white_25.0-s_24.0-fps.mp4\n",
            "building video from frames\n",
            "video ready:\n",
            "./checkpoints/glitch-circle-white/output/epoch-50_glitch-circle-white_25.0-s_24.0-fps.mp4\n"
          ]
        }
      ]
    }
  ]
}